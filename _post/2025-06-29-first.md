# 1. 대형 언어 모델 이해하기



> 이 장에서는 다음 내용을 다룹니다:
> - 대형 언어 모델(LLM)의 핵심 개념에 대한 전반적인 설명
> - LLM의 기반이 되는 트랜스포머 설계에 대한 이해 
> - LLM을 처음부터 직접 구축하기 위한 계획



대형 언어 모델(LLM : Large Language Model)들은 OpenAI의 ChatGPT와 같은 것들이며, 지난 몇 년 동안 개발된 심층 신경망 (DNN : Deep Neural Network) 모델들입니다. 이들은 자연어 처리(NLP : Natual Language Process)의 새로운 시대를 열었습니다. LLM이 등장하기 전에, 전통적인 방법은 이메일 스팸 분류와 같은 카테고리화 작업이나 손수 작성한 규칙이나 더 간단한 모델로 포착할 수 있는 직관적인 패턴 인식에서 뛰어난 성과를 보였습니다. 그러나 복잡한 이해력과 생성 능력을 요구하는 언어 작업에서는 일반적으로 부족했습니다. 예를 들어 세부 지침 분석, 맥락 분석 수행, 그리고 일관되고 맥락에 맞는 원본 텍스트 생성 등입니다. 또 다른 예로, 이전 세대의 언어 모델은 키워드 목록에서 이메일을 작성할 수 없었지만 이는 현대 LLM에게는 매우 간단한 작업입니다.

LLM은 인간 언어를 이해하고 생성하며 해석하는 뛰어난 능력을 가지고 있습니다. 그러나 "언어 모델이 이해한다"고 할 때, 이는 인간이 의식이나 이해력을 가진 것처럼 텍스트를 처리하고 생성할 수 있다는 의미가 아니라, 일관성과 맥락적 관련성을 보이는 방식으로 텍스트를 처리하고 생성할 수 있다는 의미입니다.

딥 러닝의 발전 덕분에 가능해졌으며 이는 머신러닝과 인공지능(AI)의 하위 분야로 신경망에 중점을 둡니다. LLM은 방대한 양의 텍스트 데이터를 기반으로 학습됩니다. 이러한 대규모 학습은 LLM이 이전 접근법보다 더 깊은 맥락 정보와 인간 언어의 미묘함을 포착할 수 있게 합니다. 결과적으로, LLM은 텍스트 번역과 감정 분석, 질의 응답 등 다양한 자연어 처리 작업에서 성능을 크게 향상시켰습니다.

현대적인 LLM과 이전의 NLP 모델 사이의 또 다른 중요한 차이점은 이전의 NLP 모델이 일반적으로 텍스트 분류, 언어 번역 등과 같은 특정 작업에 맞춰 설계되었지만 LLM은 다양한 NLP 작업에서 더 넓은 능력을 보여준다는 점입니다. 그 이전의 NLP 모델들은 좁은 응용 프로그램에서 뛰어난 성과를 보였습니다.

LLM의 성공은 많은 LLM의 기초가 되는 트랜스포머 설계와 LLM이 학습된 방대한 양의 데이터에 기인합니다. 이는 수작업으로 인코딩하기 어려운 다양한 언어적 뉘앙스, 맥락 및 패턴을 포착할 수 있게 합니다.

트랜스포머 설계를 기반으로 모델을 구현하고 LLM을 학습시키기 위해 대규모 훈련 데이터셋을 사용하는 변화는 NLP를 근본적으로 전환시켰습니다. 이는 인간 언어와 상호작용하는 데 더 강력한 도구를 제공했습니다.

다음의 논의는 이 책의 주요 목표, 즉 트랜스포머 설계 기반의 ChatGPT 유사 LLM을 단계별로 코드로 구현하여 LLM을 이해하는 기초를 만들어 줍니다.


### 1.1 LLM이란 무엇인가?

LLM은 인간처럼 텍스트를 이해하고 생성하며 반응하는 것을 목표로 설계된 신경망입니다. 이 모델들은 대규모의 텍스트 데이터를 기반으로 학습된 심층 신경망입니다. 때로는 인터넷에 공개되어 있는 모든 텍스트의 큰 부분을 포함할 때도 있습니다.

"대형 언어 모델"에서 "대형"은 모델의 파라미터 수와 학습 데이터셋의 규모를 의미합니다. 이러한 모델들은 종종 수 십억 또는 수 백억 개의 파라미터를 가지고 있으며, 이는 네트워크 내의 조정 가능한 가중치로 학습 중 다음 단어를 예측하기 위해 최적화됩니다.

다음 단어 예측은 언어의 고유한 순차적인 특성을 활용하여 텍스트 내에서 맥락, 구조 및 관계를 이해하도록 모델을 학습시키는 데 유용합니다. 이는 매우 단순한 작업이지만 많은 연구자들에게 이러한 작업을 통해 이렇게 강력한 모델을 생성할 수 있다는 것이 놀랍습니다. 나중에 이어지는 장에서 우리는 다음 단어 예측 학습 절차를 단계별로 논의하고 구현할 것입니다.

LLM은 예측을 할 때 입력의 다양한 부분에 선택적으로 주의를 기울일 수 있도록 하는 트랜스포머 (Transformer)라는 아키텍처를 사용합니다. 이는 인간 언어의 미묘함과 복잡성을 다루는 데 특히 능숙하게 만듭니다.

LLM이 텍스트를 생성할 수 있는 능력 덕분에, 이들은 종종 생성형 인공지능(Generative Artificial Intelligence)의 한 형태로 불리며, 흔히 생성형 AI 또는 GenAI로 약칭됩니다. 그림 1.1에 나타내듯이, 인공지능(AI)은 언어 이해, 패턴 인식, 의사결정 등 인간과 같은 지능이 필요한 작업을 수행할 수 있는 기계를 만드는 더 넓은 분야를 포함하며 그 하위 분야에는 머신러닝과 딥러닝이 있습니다.


![[Pasted image 20250415210652.png]]
***** 그림 1.1. 이러한 계층적 관계의 묘사처럼, 대형 언어 모델(LLM)은 딥러닝 기법을 적용하는 특정 사례로, 이를 통해 인간과 같은 텍스트를 처리하고 생성할 수 있습니다. 딥 러닝은 다층 신경망을 사용하는 데 초점을 맞춘 머신러닝의 특화된 분과입니다. 머신 러닝과 딥 러닝은 데이터로부터 학습하여 일반적으로 인간의 지능이 필요한 작업을 수행하도록 컴퓨터에 알고리즘을 구현하는 것을 목표로 합니다. 이러한 기술들은 복잡한 패턴을 인식하고 예측 모델을 생성하며 자연어 처리, 이미지 분류, 음성 인식 등 다양한 응용 분야에서 활용될 수 있습니다. *****


AI를 구현하기 위해 사용되는 알고리즘은 머신 러닝의 주요 연구 대상이 됩니다. 특히, 머신 러닝은 데이터에 대해 명시적으로 프로그래밍되지 않으면서도 데이터를 기반으로 학습하고 예측하거나 결정을 내리는 데 필요한 알고리즘을 개발하는 것을 포함합니다. 

예를 들어 스팸 필터가 머신 러닝의 실제 적용 사례를 잘 보여줍니다. 스팸 이메일을 수동으로 식별하기 위해 규칙을 작성하지 않고, 대신 머신 러닝 알고리즘에 스팸과 정당한 이메일로 라벨된 이메일의 예시들을 제공합니다. 학습 데이터셋에서 예측 오차를 최소화함으로써 모델은 스팸의 패턴과 특징을 인식하는 방법을 배웁니다. 이는 새로운 이메일을 스팸인지 아니면 그렇지 않은지 분류할 수 있게 합니다.

그림 1.1에서 보여진 것처럼, 딥 러닝은 세 개 이상의 층(심층 신경망 또는 딥 뉴럴 네트워크로도 불림)을 사용하는 신경망을 활용하여 데이터 내의 복잡한 패턴과 추상을 모델링하는 데 중점을 둔 머신 러닝의 하위 집합입니다.

딥 러닝과는 달리, 전통적인 머신 러닝은 수동 특성 추출을 필요로 합니다. 이는 인간 전문가가 모델에 가장 관련성 있는 특징을 식별하고 선택해야 한다는 것을 의미합니다.

머신 러닝과 딥 러닝이 현재 AI 분야를 주도하고 있지만, AI는 규칙 기반 시스템, 유전 알고리즘, 전문가 시스템, 퍼지 논리 또는 기호적 추론 같은 다른 접근법도 포함하고 있습니다.

스팸 분류 예로 돌아가면, 전통적인 머신 러닝에서는 인간 전문가가 이메일 텍스트에서 특성을 수동으로 추출할 수 있습니다. 예를 들어 특정 트리거 단어("경품", "당첨", "무료")의 빈도, 느낌표의 수, 대문자 단어 사용 여부, 또는 의심스러운 링크의 존재 여부입니다. 이러한 전문가 정의 특성에 기반한 데이터셋은 모델을 학습시키기 위해 사용됩니다.

반면 딥 러닝은 수동으로 특성을 추출할 필요가 없습니다. 이는 인간 전문가가 딥 러닝 모델에 가장 관련성 있는 특성을 식별하고 선택할 필요가 없음을 의미합니다. 그러나 전통적인 머신 러닝과 스팸 분류를 위한 딥 러닝 모두 전문가나 사용자가 수집한 레이블, 예를 들어 스팸(정답) 또는 비스팸(오답)이 여전히 필요합니다.

이제 LLM들이 해결할 수 있는 몇 가지 문제, LLM들이 해결하는 도전 과제, 그리고 나중에 구현할 일반적인 LLM 아키텍처를 살펴봅시다.
